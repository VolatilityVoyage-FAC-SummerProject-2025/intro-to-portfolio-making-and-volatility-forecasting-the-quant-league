{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "c63HNKpuy8-2"
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "7PzcG6z2zO_2"
   },
   "outputs": [],
   "source": [
    "nifty50_tickers = [\n",
    "    'RELIANCE.NS', 'TCS.NS', 'INFY.NS', 'HDFCBANK.NS', 'ICICIBANK.NS', 'HINDUNILVR.NS',\n",
    "    'SBIN.NS', 'LT.NS', 'KOTAKBANK.NS', 'ITC.NS', 'BHARTIARTL.NS', 'ASIANPAINT.NS',\n",
    "    'AXISBANK.NS', 'HCLTECH.NS', 'BAJFINANCE.NS', 'MARUTI.NS', 'SUNPHARMA.NS', 'WIPRO.NS',\n",
    "    'ULTRACEMCO.NS', 'TITAN.NS', 'HINDALCO.NS', 'NTPC.NS', 'JSWSTEEL.NS', 'TECHM.NS',\n",
    "    'POWERGRID.NS', 'TATAMOTORS.NS', 'GRASIM.NS', 'ADANIENT.NS', 'COALINDIA.NS',\n",
    "    'ONGC.NS', 'NESTLEIND.NS', 'BPCL.NS', 'UPL.NS', 'EICHERMOT.NS', 'DRREDDY.NS',\n",
    "    'DIVISLAB.NS', 'HEROMOTOCO.NS', 'BAJAJFINSV.NS', 'CIPLA.NS', 'HDFCLIFE.NS',\n",
    "    'SHREECEM.NS', 'SBILIFE.NS', 'INDUSINDBK.NS', 'BRITANNIA.NS', 'BAJAJ-AUTO.NS',\n",
    "    'TATACONSUM.NS', 'APOLLOHOSP.NS', 'M&M.NS'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l4QVmC3fzPCN",
    "outputId": "8222b809-4372-4f04-f385-11eefc9d6dd0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get ticker 'ULTRACEMCO.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to get ticker 'DIVISLAB.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to get ticker 'TITAN.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[                       0%                       ]Failed to get ticker 'GRASIM.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to get ticker 'AXISBANK.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**                     4%                       ]  2 of 48 completedFailed to get ticker 'SBILIFE.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[****                   8%                       ]  4 of 48 completedFailed to get ticker 'TATAMOTORS.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[*****                 10%                       ]  5 of 48 completedFailed to get ticker 'SUNPHARMA.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to get ticker 'SHREECEM.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[******                12%                       ]  6 of 48 completedFailed to get ticker 'TCS.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[*******               15%                       ]  7 of 48 completedFailed to get ticker 'BAJFINANCE.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to get ticker 'LT.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[*********             19%                       ]  9 of 48 completedFailed to get ticker 'BHARTIARTL.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[***********           23%                       ]  11 of 48 completedFailed to get ticker 'BRITANNIA.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[************          25%                       ]  12 of 48 completedFailed to get ticker 'M&M.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[************          25%                       ]  12 of 48 completedFailed to get ticker 'KOTAKBANK.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[***************       31%                       ]  15 of 48 completedFailed to get ticker 'WIPRO.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to get ticker 'ASIANPAINT.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[*****************     35%                       ]  17 of 48 completedFailed to get ticker 'UPL.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[******************    38%                       ]  18 of 48 completedFailed to get ticker 'ICICIBANK.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[*******************   40%                       ]  19 of 48 completedFailed to get ticker 'POWERGRID.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to get ticker 'BAJAJ-AUTO.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[********************  42%                       ]  20 of 48 completedFailed to get ticker 'APOLLOHOSP.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[********************  42%                       ]  20 of 48 completedFailed to get ticker 'HEROMOTOCO.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**********************46%                       ]  22 of 48 completedFailed to get ticker 'HDFCLIFE.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**********************48%                       ]  23 of 48 completedFailed to get ticker 'ONGC.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to get ticker 'RELIANCE.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**********************52%                       ]  25 of 48 completedFailed to get ticker 'COALINDIA.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**********************56%**                     ]  27 of 48 completedFailed to get ticker 'HINDALCO.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to get ticker 'MARUTI.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**********************58%***                    ]  28 of 48 completedFailed to get ticker 'TATACONSUM.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**********************60%****                   ]  29 of 48 completedFailed to get ticker 'HINDUNILVR.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**********************62%*****                  ]  30 of 48 completedFailed to get ticker 'JSWSTEEL.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**********************65%******                 ]  31 of 48 completedFailed to get ticker 'CIPLA.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**********************69%********               ]  33 of 48 completedFailed to get ticker 'HDFCBANK.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to get ticker 'HCLTECH.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**********************71%*********              ]  34 of 48 completedFailed to get ticker 'TECHM.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**********************73%**********             ]  35 of 48 completedFailed to get ticker 'BAJAJFINSV.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**********************77%************           ]  37 of 48 completedFailed to get ticker 'ITC.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to get ticker 'NESTLEIND.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**********************79%*************          ]  38 of 48 completedFailed to get ticker 'INDUSINDBK.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**********************83%***************        ]  40 of 48 completedFailed to get ticker 'BPCL.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**********************85%****************       ]  41 of 48 completedFailed to get ticker 'NTPC.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**********************88%*****************      ]  42 of 48 completedFailed to get ticker 'DRREDDY.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to get ticker 'SBIN.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**********************90%******************     ]  43 of 48 completedFailed to get ticker 'EICHERMOT.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to get ticker 'ADANIENT.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[**********************94%********************   ]  45 of 48 completedFailed to get ticker 'INFY.NS' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[*********************100%***********************]  47 of 48 completed\n",
      "\n",
      "48 Failed downloads:\n",
      "['ULTRACEMCO.NS', 'DIVISLAB.NS', 'TITAN.NS', 'GRASIM.NS', 'AXISBANK.NS', 'SBILIFE.NS', 'TATAMOTORS.NS', 'SUNPHARMA.NS', 'SHREECEM.NS', 'TCS.NS', 'BAJFINANCE.NS', 'LT.NS', 'BHARTIARTL.NS', 'BRITANNIA.NS', 'M&M.NS', 'KOTAKBANK.NS', 'WIPRO.NS', 'ASIANPAINT.NS', 'UPL.NS', 'ICICIBANK.NS', 'POWERGRID.NS', 'BAJAJ-AUTO.NS', 'APOLLOHOSP.NS', 'HEROMOTOCO.NS', 'HDFCLIFE.NS', 'ONGC.NS', 'RELIANCE.NS', 'COALINDIA.NS', 'HINDALCO.NS', 'MARUTI.NS', 'TATACONSUM.NS', 'HINDUNILVR.NS', 'JSWSTEEL.NS', 'CIPLA.NS', 'HDFCBANK.NS', 'HCLTECH.NS', 'TECHM.NS', 'BAJAJFINSV.NS', 'ITC.NS', 'NESTLEIND.NS', 'INDUSINDBK.NS', 'BPCL.NS', 'NTPC.NS', 'DRREDDY.NS', 'SBIN.NS', 'EICHERMOT.NS', 'ADANIENT.NS', 'INFY.NS']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  47 of 48 completed"
     ]
    }
   ],
   "source": [
    "data = yf.download(nifty50_tickers, start='2022-01-01', end='2024-09-01')['Close']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "sV4oW-3KzPER"
   },
   "outputs": [],
   "source": [
    "data = data.ffill().bfill() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9BjmP-JzPGX",
    "outputId": "8137249b-d2ee-46e0-896f-08e572131444"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker\n",
      "ADANIENT.NS      0\n",
      "APOLLOHOSP.NS    0\n",
      "JSWSTEEL.NS      0\n",
      "KOTAKBANK.NS     0\n",
      "LT.NS            0\n",
      "M&M.NS           0\n",
      "MARUTI.NS        0\n",
      "NESTLEIND.NS     0\n",
      "NTPC.NS          0\n",
      "ONGC.NS          0\n",
      "POWERGRID.NS     0\n",
      "RELIANCE.NS      0\n",
      "SBILIFE.NS       0\n",
      "SBIN.NS          0\n",
      "SHREECEM.NS      0\n",
      "SUNPHARMA.NS     0\n",
      "TATACONSUM.NS    0\n",
      "TATAMOTORS.NS    0\n",
      "TCS.NS           0\n",
      "TECHM.NS         0\n",
      "TITAN.NS         0\n",
      "ULTRACEMCO.NS    0\n",
      "UPL.NS           0\n",
      "ITC.NS           0\n",
      "INFY.NS          0\n",
      "INDUSINDBK.NS    0\n",
      "COALINDIA.NS     0\n",
      "ASIANPAINT.NS    0\n",
      "AXISBANK.NS      0\n",
      "BAJAJ-AUTO.NS    0\n",
      "BAJAJFINSV.NS    0\n",
      "BAJFINANCE.NS    0\n",
      "BHARTIARTL.NS    0\n",
      "BPCL.NS          0\n",
      "BRITANNIA.NS     0\n",
      "CIPLA.NS         0\n",
      "DIVISLAB.NS      0\n",
      "ICICIBANK.NS     0\n",
      "DRREDDY.NS       0\n",
      "EICHERMOT.NS     0\n",
      "GRASIM.NS        0\n",
      "HCLTECH.NS       0\n",
      "HDFCBANK.NS      0\n",
      "HDFCLIFE.NS      0\n",
      "HEROMOTOCO.NS    0\n",
      "HINDALCO.NS      0\n",
      "HINDUNILVR.NS    0\n",
      "WIPRO.NS         0\n",
      "dtype: int64\n",
      "(0, 48)\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum().sort_values(ascending=False))  # should be all 0 if clean\n",
    "print(data.shape)\n",
    "# displays the number of missing values in each column\n",
    "# .shape return the number of rows and columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "x54fmltfzPId"
   },
   "outputs": [],
   "source": [
    "returns = data.pct_change().dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "NPghgckfzPKR"
   },
   "outputs": [],
   "source": [
    "rolling_vol = returns.rolling(window=20).std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "knWiowR1zPMn"
   },
   "outputs": [],
   "source": [
    "rolling_vol = rolling_vol.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "0rsIfY1gzPOt"
   },
   "outputs": [],
   "source": [
    "vol_df = rolling_vol.copy()\n",
    "vol_df.columns.name = 'Ticker'\n",
    "vol_df.index.name = 'Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iajD1UaRzPQy",
    "outputId": "7834fc1a-1408-408a-ce3f-e202bdcd5604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling Volatility (first 5 rows):\n",
      "Empty DataFrame\n",
      "Columns: [ADANIENT.NS, APOLLOHOSP.NS, ASIANPAINT.NS, AXISBANK.NS, BAJAJ-AUTO.NS, BAJAJFINSV.NS, BAJFINANCE.NS, BHARTIARTL.NS, BPCL.NS, BRITANNIA.NS, CIPLA.NS, COALINDIA.NS, DIVISLAB.NS, DRREDDY.NS, EICHERMOT.NS, GRASIM.NS, HCLTECH.NS, HDFCBANK.NS, HDFCLIFE.NS, HEROMOTOCO.NS, HINDALCO.NS, HINDUNILVR.NS, ICICIBANK.NS, INDUSINDBK.NS, INFY.NS, ITC.NS, JSWSTEEL.NS, KOTAKBANK.NS, LT.NS, M&M.NS, MARUTI.NS, NESTLEIND.NS, NTPC.NS, ONGC.NS, POWERGRID.NS, RELIANCE.NS, SBILIFE.NS, SBIN.NS, SHREECEM.NS, SUNPHARMA.NS, TATACONSUM.NS, TATAMOTORS.NS, TCS.NS, TECHM.NS, TITAN.NS, ULTRACEMCO.NS, UPL.NS, WIPRO.NS]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Rolling Volatility (first 5 rows):\")\n",
    "print(vol_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "IXeZVvDTzPU9"
   },
   "outputs": [],
   "source": [
    "# Rolling Mean Forecast (5-day rolling mean of the 20-day rolling volatility)\n",
    "vol_forecast_rm = rolling_vol.rolling(window=5).mean()\n",
    "\n",
    "#we are applying another rolling window, this time of size 5 days.\n",
    "# For each day, this looks at the most recent 5 days of volatility estimates.\n",
    "# The result is stored in a new DataFrame called vol_forecast_rm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "re1ki2yGzPXj"
   },
   "outputs": [],
   "source": [
    "# EWMA Forecast (lambda = 0.94)\n",
    "lambda_ = 0.9\n",
    "# Higher Î» (closer to 1) means more weight on past observations and slower reaction to new data.\n",
    "\n",
    "vol_squared = returns ** 2\n",
    "ewma_vol = vol_squared.ewm(alpha=1 - lambda_).mean() ** 0.5\n",
    "# .ewm(alpha=1 - Î») applies an Exponentially Weighted Moving Average with decay controlled by Î± = 1 - Î» = 0.06.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmIaPnXEzPZX",
    "outputId": "c1402957-6b70-415e-c247-53cdd1ca179d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\nipun\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg # a tool for time series forecasting.\n",
    "\n",
    "ar1_forecast = {}\n",
    "# Initializes an empty dictionary to store the AR(1) forecasted volatility for each ticker.\n",
    "\n",
    "for ticker in rolling_vol.columns:\n",
    "# Loops through each ticker/asset in your volatility DataFrame (rolling_vol).\n",
    "    series = rolling_vol[ticker].dropna()\n",
    "    # Selects the rolling volatility series for a given ticker and drops NaN values.\n",
    "    try:\n",
    "        model = AutoReg(series, lags=1).fit()\n",
    "        #Fits an AR(1) model to the time series:\n",
    "        forecast = model.predict(start=len(series), end=len(series))\n",
    "        # Forecasts the next value (i.e., next-period volatility).\n",
    "\n",
    "        ar1_forecast[ticker] = forecast.values[0]\n",
    "    except Exception as e:\n",
    "        ar1_forecast[ticker] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMzm-1ql3oiT",
    "outputId": "349d6845-e938-45a1-8392-44c732c21514"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get latest values from Rolling and EWMA methods\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m last_rolling \u001b[38;5;241m=\u001b[39m rolling_vol\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Gets the most recent (last) 20-day rolling volatility for all tickers\u001b[39;00m\n\u001b[0;32m      4\u001b[0m last_rm \u001b[38;5;241m=\u001b[39m vol_forecast_rm\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1752\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1683\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# Get latest values from Rolling and EWMA methods\n",
    "last_rolling = rolling_vol.iloc[-1]\n",
    "# Gets the most recent (last) 20-day rolling volatility for all tickers\n",
    "last_rm = vol_forecast_rm.iloc[-1]\n",
    "# Gets the last available 5-day smoothed rolling mean of volatility.\n",
    "last_ewma = ewma_vol.iloc[-1]\n",
    "# Gets the most recent EWMA volatility estimate.\n",
    "ar1_series = pd.Series(ar1_forecast)\n",
    "# Converts your dictionary of AR(1) forecasts into a Pandas Series\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "forecast_df = pd.DataFrame({\n",
    "    'Rolling': last_rolling,\n",
    "    'Rolling_Mean': last_rm,\n",
    "    'EWMA': last_ewma,\n",
    "    'AR1': ar1_series\n",
    "})\n",
    "\n",
    "# Drop any rows with missing forecasts\n",
    "forecast_df = forecast_df.dropna()\n",
    "\n",
    "# Preview the forecasts\n",
    "print(forecast_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzSt1axP3ok2",
    "outputId": "446265de-8898-41b4-ea07-d611bea27257"
   },
   "outputs": [],
   "source": [
    "\n",
    "selected_forecast = forecast_df['EWMA']\n",
    "\n",
    "\n",
    "normalized_vol = (selected_forecast - selected_forecast.min()) / (selected_forecast.max() - selected_forecast.min())\n",
    "\n",
    "\n",
    "normalized_df = pd.DataFrame({\n",
    "    'Forecasted_Volatility': selected_forecast,\n",
    "    'Normalized_Volatility': normalized_vol\n",
    "})\n",
    "\n",
    "print(normalized_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hx6Bk19h3onM"
   },
   "outputs": [],
   "source": [
    "\n",
    "risk_score = 0.2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2Jr3BHQ3opi",
    "outputId": "1efc3677-9a3f-4fdc-af34-160227e55c22"
   },
   "outputs": [],
   "source": [
    "\n",
    "normalized_df['Distance'] = abs(normalized_df['Normalized_Volatility'] - risk_score)\n",
    "\n",
    "matched_stocks = normalized_df.sort_values(by='Distance').head(3)\n",
    "\n",
    "print(\"Top 3 matched stocks based on investor profile:\")\n",
    "print(matched_stocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J5G4kV5q351h",
    "outputId": "e3521383-bf48-4b96-b4ce-dfb05eb18ce1"
   },
   "outputs": [],
   "source": [
    "selected_tickers = matched_stocks.index.tolist()\n",
    "print(\"Selected Tickers:\", selected_tickers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O50CRfQN356e",
    "outputId": "5e2da056-bbf2-45b2-a409-3ec8deea407d"
   },
   "outputs": [],
   "source": [
    "inv_vol = 1 / matched_stocks['Forecasted_Volatility']\n",
    "inv_weights = inv_vol / inv_vol.sum()\n",
    "weights_inverse_vol = inv_weights.to_dict()\n",
    "print(\"Inverse Volatility Weights:\", weights_inverse_vol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1dtlW0PS358k",
    "outputId": "b4b856b4-9d85-49a9-fc1c-603c14cee4ba"
   },
   "outputs": [],
   "source": [
    "initial_investment = 10_00_000  # 10 lakhs\n",
    "num_selected_stocks = len(selected_tickers)\n",
    "if num_selected_stocks > 0:\n",
    "    equal_weight = 1 / num_selected_stocks\n",
    "    weights_equal = {ticker: equal_weight for ticker in selected_tickers}\n",
    "else:\n",
    "    weights_equal = {} # Handle the case where no tickers were selected\n",
    "\n",
    "# Choose weight strategy\n",
    "# Uncomment the line you want to use\n",
    "weights = weights_equal         # Use equal weights\n",
    "# weights = weights_inverse_vol # Or use inverse volatility weights\n",
    "\n",
    "# Allocate capital per stock\n",
    "capital_allocations = {ticker: weight * initial_investment for ticker, weight in weights.items()}\n",
    "print(\"Capital Allocation:\")\n",
    "print(capital_allocations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I2MTpcVA35-H",
    "outputId": "9d55fb17-02e1-4166-97ed-94f446c81e05"
   },
   "outputs": [],
   "source": [
    "# You may already have this data, but in case:\n",
    "backtest_data = yf.download(selected_tickers, start='2022-01-01', end='2025-01-01')['Close']\n",
    "backtest_data = backtest_data.ffill().bfill()  # Fill missing values\n",
    "\n",
    "print(\"Backtest Price Data (Head):\")\n",
    "print(backtest_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "id": "FJN579u036Cj",
    "outputId": "6764a503-12f1-448c-89ad-281286dfe85e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Selected tickers\n",
    "selected_tickers = ['APOLLOHOSP.NS', 'AXISBANK.NS', 'DRREDDY.NS']\n",
    "\n",
    "# Weights based on inverse volatility (already computed earlier)\n",
    "weights_inverse_vol = {\n",
    "    'APOLLOHOSP.NS': 0.376714,\n",
    "    'AXISBANK.NS': 0.276143,\n",
    "    'DRREDDY.NS': 0.347143\n",
    "}\n",
    "weights = weights_inverse_vol  # You can switch to equal if needed\n",
    "\n",
    "# Capital allocation\n",
    "initial_investment = 10_00_000  # â‚¹10 Lakhs\n",
    "capital_allocations = {ticker: weight * initial_investment for ticker, weight in weights.items()}\n",
    "\n",
    "# Backtest price data (already downloaded)\n",
    "# Use 'backtest_data' that you already downloaded earlier\n",
    "# backtest_data = yf.download(selected_tickers, start='2022-01-01', end='2025-01-01')['Close']\n",
    "# backtest_data = backtest_data.ffill().bfill()\n",
    "\n",
    "# Compute daily returns\n",
    "daily_returns = backtest_data.pct_change().dropna()\n",
    "\n",
    "# Portfolio returns using weights\n",
    "portfolio_returns = daily_returns.dot(np.array([weights[t] for t in selected_tickers]))\n",
    "\n",
    "# Cumulative returns\n",
    "cumulative_returns = (1 + portfolio_returns).cumprod()\n",
    "\n",
    "# Scale to initial investment\n",
    "portfolio_value = cumulative_returns * initial_investment\n",
    "\n",
    "# Plot portfolio value\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(portfolio_value, label='Buy & Hold Portfolio', color='green')\n",
    "plt.title('Buy & Hold Portfolio Performance (2022â€“2025)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value (â‚¹)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Portfolio metrics\n",
    "final_value = portfolio_value.iloc[-1]\n",
    "total_return = (final_value - initial_investment) / initial_investment\n",
    "annualized_return = portfolio_returns.mean() * 252\n",
    "annualized_volatility = portfolio_returns.std() * np.sqrt(252)\n",
    "sharpe_ratio = annualized_return / annualized_volatility\n",
    "\n",
    "# Print results\n",
    "print(f\" Final Portfolio Value: â‚¹{final_value:,.2f}\")\n",
    "print(f\" Total Return: {total_return:.2%}\")\n",
    "print(f\" Annualized Return: {annualized_return:.2%}\")\n",
    "print(f\" Annualized Volatility: {annualized_volatility:.2%}\")\n",
    "print(f\" Sharpe Ratio: {sharpe_ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "id": "1uUI1hKl6icm",
    "outputId": "22c211d9-2a78-4365-bf6b-44fd81014806"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_macd_atr_strategy(price_df, ticker, k=2):\n",
    "    df = price_df[[ticker]].dropna().copy()\n",
    "    df.rename(columns={ticker: 'Close'}, inplace=True)\n",
    "\n",
    "    # MACD Calculation\n",
    "    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = df['EMA12'] - df['EMA26']\n",
    "    df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "    \n",
    "    df['High'] = df['Close']\n",
    "    df['Low'] = df['Close']\n",
    "    df['PrevClose'] = df['Close'].shift(1)\n",
    "\n",
    "    # Corrected calculation for True Range\n",
    "    df['TR'] = df[['High', 'Low']].max(axis=1) - df[['Low', 'PrevClose']].min(axis=1)\n",
    "\n",
    "    df['ATR'] = df['TR'].rolling(window=14).mean()\n",
    "\n",
    "    # Signals\n",
    "    df['Position'] = 0\n",
    "    # Enter position when MACD crosses above Signal\n",
    "    df.loc[df['MACD'] > df['Signal'], 'Position'] = 1\n",
    "    # Exit position when MACD crosses below Signal (this might be too simplistic for an exit)\n",
    "    df.loc[df['MACD'] < df['Signal'], 'Position'] = 0\n",
    "    df['Position'] = df['Position'].ffill() # Forward fill to maintain position until explicitly exited\n",
    "\n",
    "    # Trailing Stop-loss\n",
    "    # Track the highest close price reached while in a long position\n",
    "    df['Peak'] = df['Close'].where(df['Position'] == 1).cummax()\n",
    "    # Calculate the stop-loss level\n",
    "    df['StopLoss'] = df['Peak'] - k * df['ATR']\n",
    "    # Identify exit signals based on price falling below stop-loss while in a long position\n",
    "    df['Exit'] = (df['Close'] < df['StopLoss']) & (df['Position'] == 1)\n",
    "\n",
    "    # Apply stop-loss exits iteratively\n",
    "    in_trade = False\n",
    "    # Iterate through the DataFrame to apply the stop-loss logic\n",
    "    for i in range(1, len(df)):\n",
    "        # If currently in a trade\n",
    "        if in_trade:\n",
    "            # Check if the stop-loss exit condition is met for the current row\n",
    "            if df.iloc[i]['Exit']:\n",
    "                # If exit condition is met, set the position for the current row to 0\n",
    "                df.iat[i, df.columns.get_loc('Position')] = 0\n",
    "                # Set in_trade flag to False as the position is exited\n",
    "                in_trade = False\n",
    "        # If not currently in a trade\n",
    "        else:\n",
    "            \n",
    "            if df.iloc[i]['Position'] == 1 and df.iloc[i - 1]['Position'] == 0:\n",
    "                # If a new position is initiated, set in_trade flag to True\n",
    "                in_trade = True\n",
    "\n",
    "    \n",
    "    df['Strategy_Return'] = df['Position'].shift(1) * df['Close'].pct_change()\n",
    "   \n",
    "    df['Cumulative'] = (1 + df['Strategy_Return']).cumprod()\n",
    "\n",
    "    return df[['Close', 'MACD', 'Signal', 'Position', 'Strategy_Return', 'Cumulative']]\n",
    "\n",
    "# Run strategy for each selected stock\n",
    "results = {}\n",
    "for ticker in selected_tickers:\n",
    "    # Ensure backtest_data is available and correctly structured\n",
    "    if ticker in backtest_data.columns:\n",
    "        results[ticker] = compute_macd_atr_strategy(backtest_data, ticker)\n",
    "    else:\n",
    "        print(f\"Warning: Data for {ticker} not found in backtest_data.\")\n",
    "        results[ticker] = pd.DataFrame() # Add an empty DataFrame to avoid errors\n",
    "\n",
    "# Combine Portfolio Returns\n",
    "# Filter out tickers for which no data was available or processing failed\n",
    "valid_tickers = [t for t in selected_tickers if not results[t].empty]\n",
    "\n",
    "if valid_tickers:\n",
    "    # Sum the weighted returns for valid tickers\n",
    "    combined_returns = sum(results[t]['Strategy_Return'].fillna(0) * weights[t] for t in valid_tickers)\n",
    "    # Calculate the cumulative returns for the portfolio, scaled by initial investment\n",
    "    combined_cum_returns = (1 + combined_returns).cumprod() * initial_investment\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(combined_cum_returns, label='MACD + ATR Strategy', color='blue')\n",
    "    plt.title('MACD + ATR Portfolio Performance')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Portfolio Value (â‚¹)')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Metrics\n",
    "    final_val = combined_cum_returns.iloc[-1]\n",
    "    total_ret = (final_val - initial_investment) / initial_investment\n",
    "    # Annualize returns assuming 252 trading days in a year\n",
    "    ann_ret = combined_returns.mean() * 252\n",
    "    # Annualize volatility\n",
    "    ann_vol = combined_returns.std() * np.sqrt(252)\n",
    "    # Calculate Sharpe Ratio (assuming risk-free rate is 0 for simplicity)\n",
    "    sharpe = ann_ret / ann_vol\n",
    "\n",
    "    print(f\"ðŸ“ˆ Final Value: â‚¹{final_val:,.2f}\")\n",
    "    print(f\"âœ… Total Return: {total_ret:.2%}\")\n",
    "    print(f\"ðŸ“… Annualized Return: {ann_ret:.2%}\")\n",
    "    print(f\"âš ï¸ Annualized Volatility: {ann_vol:.2%}\")\n",
    "    print(f\"ðŸ“Š Sharpe Ratio: {sharpe:.2f}\")\n",
    "else:\n",
    "    print(\"No valid tickers processed for the MACD + ATR strategy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "id": "BemXqy7G-SD6",
    "outputId": "771b1cfe-5422-4859-a947-eecc661ea764"
   },
   "outputs": [],
   "source": [
    "# Rename and align both strategies\n",
    "buy_hold_value = portfolio_value.rename('Buy & Hold')\n",
    "macd_atr_value = combined_cum_returns.rename('MACD + ATR')\n",
    "\n",
    "# Align the two series strictly on overlapping dates only\n",
    "comparison_df = pd.concat([buy_hold_value, macd_atr_value], axis=1).dropna()\n",
    "\n",
    "# Replot with aligned data\n",
    "plt.figure(figsize=(18, 10))\n",
    "plt.plot(comparison_df.index, comparison_df['Buy & Hold'], label='Buy & Hold', color='green')\n",
    "plt.plot(comparison_df.index, comparison_df['MACD + ATR'], label='MACD + ATR', color='blue')\n",
    "plt.title('ðŸ“Š Portfolio Strategy Comparison (Aligned)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value (â‚¹)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kDMqg_j08SC9",
    "outputId": "38d40fd2-c1ec-461b-9e54-bb45e0c18e0a"
   },
   "outputs": [],
   "source": [
    "print(\" Strategy Comparison Summary:\")\n",
    "print(f\"{'Metric':<25}{'Buy & Hold':<20}{'MACD + ATR':<20}\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'Final Value (â‚¹)':<25}{buy_hold_value.iloc[-1]:<20,.2f}{macd_atr_value.iloc[-1]:<20,.2f}\")\n",
    "print(f\"{'Total Return':<25}{(buy_hold_value.iloc[-1]/initial_investment - 1):<20.2%}{(macd_atr_value.iloc[-1]/initial_investment - 1):<20.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1VkHIauAT36",
    "outputId": "ee121dc1-6f7e-4b8f-b5d9-101836e99c44"
   },
   "outputs": [],
   "source": [
    "print(\"ðŸ—“ Date Range Used for Comparison:\", comparison_df.index.min().date(), \"to\", comparison_df.index.max().date())\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
